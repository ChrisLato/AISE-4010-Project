{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gpd = pd.read_csv('data/gdp.csv', index_col='Year')\n",
    "inflation = pd.read_csv('data/inflation.csv', index_col='date')\n",
    "unemployment = pd.read_csv('data/unemployment.csv')\n",
    "yield_data = pd.read_csv('data/yield.csv') #61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yield curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LongTermRate     Slope  Curvature1  Curvature2  ForwardRate1Y  \\\n",
      "Date                                                                        \n",
      "1961-06-30      0.160110  0.463769    0.000000         0.0       0.233760   \n",
      "1961-07-31      0.164034  0.446137    0.000000         0.0       0.230211   \n",
      "1961-08-31      0.169935  0.452569    0.000000         0.0       0.236753   \n",
      "1961-09-30      0.165211  0.453090    0.000000         0.0       0.237257   \n",
      "1961-10-31      0.152620  0.455216    0.113939         0.0       0.230314   \n",
      "\n",
      "            ForwardRate4Y  ForwardRate9Y   SVENF01   SVENF02   SVENF03  ...  \\\n",
      "Date                                                                    ...   \n",
      "1961-06-30       0.247301            NaN  3.533592  3.934585  3.993169  ...   \n",
      "1961-07-31       0.254123            NaN  3.436640  3.934995  4.062475  ...   \n",
      "1961-08-31       0.264753            NaN  3.522839  4.054435  4.201822  ...   \n",
      "1961-09-30       0.256468            NaN  3.581385  4.014040  4.108765  ...   \n",
      "1961-10-31       0.247019            NaN  3.489457  3.907943  4.016624  ...   \n",
      "\n",
      "             SVENY02   SVENY03   SVENY04   SVENY05   SVENY06   SVENY07  \\\n",
      "Date                                                                     \n",
      "1961-06-30  3.383562  3.580031  3.684631  3.748146  3.790554  3.820877   \n",
      "1961-07-31  3.289770  3.531040  3.668470  3.754025  3.811640  3.852910   \n",
      "1961-08-31  3.420465  3.661852  3.802339  3.890426  3.949861  3.992443   \n",
      "1961-09-30  3.445030  3.654595  3.770960  3.842475  3.890400  3.924650   \n",
      "1961-10-31  3.350962  3.559624  3.674895  3.739548  3.776095  3.796800   \n",
      "\n",
      "            SVENY08  SVENY09  SVENY10      TAU1  \n",
      "Date                                             \n",
      "1961-06-30      NaN      NaN      NaN  0.386493  \n",
      "1961-07-31      NaN      NaN      NaN  0.565912  \n",
      "1961-08-31      NaN      NaN      NaN  0.565608  \n",
      "1961-09-30      NaN      NaN      NaN  0.492659  \n",
      "1961-10-31      NaN      NaN      NaN  1.505942  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert to datetime\n",
    "yield_data['Date'] = pd.to_datetime(yield_data['Date'], errors='coerce')\n",
    "\n",
    "# Replace invalid values with NaN\n",
    "yield_data.replace(-999.99, pd.NA, inplace=True)\n",
    "\n",
    "# Drop columns with more than 20% missing values\n",
    "threshold = 0.2 * len(yield_data)\n",
    "columns_to_drop = yield_data.columns[yield_data.isnull().sum() > threshold]\n",
    "yield_data_cleaned = yield_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Rename columns \n",
    "column_rename_mapping = {\n",
    "    'BETA0': 'LongTermRate',\n",
    "    'BETA1': 'Slope',\n",
    "    'BETA2': 'Curvature1',\n",
    "    'BETA3': 'Curvature2',\n",
    "}\n",
    "\n",
    "for i in range(1, 31):\n",
    "    column_rename_mapping[f'SVENPY{i:02d}'] = f'SpotRate{i}Y'\n",
    "\n",
    "\n",
    "for i in range(1, 31):\n",
    "    column_rename_mapping[f'SVEN1F{i:02d}'] = f'ForwardRate{i}Y'\n",
    "\n",
    "yield_data_cleaned.rename(columns=column_rename_mapping, inplace=True)\n",
    "\n",
    "# Drop rows where 'Date' or key features are missing\n",
    "key_features = ['Date', 'LongTermRate', 'ForwardRate1Y']\n",
    "yield_data_cleaned = yield_data_cleaned.dropna(subset=key_features)\n",
    "\n",
    "# Set Date as the index for resampling\n",
    "yield_data_cleaned.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample to monthly frequency\n",
    "monthly_data = yield_data_cleaned.resample('M').mean()\n",
    "\n",
    "# Interpolate missing values for continuous features\n",
    "monthly_data_interpolated = monthly_data.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "# Logarithmic transformation to reduce skewness for curvature columns\n",
    "curvature_columns = ['Curvature1', 'Curvature2']\n",
    "for column in curvature_columns:\n",
    "    monthly_data_interpolated[column] = monthly_data_interpolated[column].apply(\n",
    "        lambda x: np.log1p(x) if x > 0 else 0\n",
    "    )\n",
    "\n",
    "# Normalize continuous features to the range [0, 1]\n",
    "continuous_features = [\n",
    "    col for col in monthly_data_interpolated.columns if col.startswith('LongTermRate') or col.startswith('Slope')\n",
    "    or col.startswith('Curvature') or col.startswith('SpotRate') or col.startswith('ForwardRate')\n",
    "]\n",
    "monthly_data_interpolated[continuous_features] = monthly_data_interpolated[continuous_features].apply(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min()), axis=0\n",
    ")\n",
    "\n",
    "# Final Output: Display the first few rows of the processed dataset\n",
    "print(monthly_data_interpolated.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 917 entries, 0 to 916\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   date               917 non-null    object \n",
      " 1   overall_rate       917 non-null    float64\n",
      " 2   men_rate           917 non-null    float64\n",
      " 3   women_rate         917 non-null    float64\n",
      " 4   men_16_17_rate     917 non-null    float64\n",
      " 5   women_16_17_rate   917 non-null    float64\n",
      " 6   men_16_19_rate     917 non-null    float64\n",
      " 7   women_16_19_rate   917 non-null    float64\n",
      " 8   men_18_19_rate     917 non-null    float64\n",
      " 9   women_18_19_rate   917 non-null    float64\n",
      " 10  men_16_24_rate     917 non-null    float64\n",
      " 11  women_16_24_rate   917 non-null    float64\n",
      " 12  men_20_24_rate     917 non-null    float64\n",
      " 13  women_20_24_rate   917 non-null    float64\n",
      " 14  men_25plus_rate    917 non-null    float64\n",
      " 15  women_25plus_rate  917 non-null    float64\n",
      " 16  men_25_34_rate     917 non-null    float64\n",
      " 17  women_25_34_rate   917 non-null    float64\n",
      " 18  men_25_54_rate     917 non-null    float64\n",
      " 19  women_25_54_rate   917 non-null    float64\n",
      " 20  men_35_44_rate     917 non-null    float64\n",
      " 21  women_35_44_rate   917 non-null    float64\n",
      " 22  men_45_54_rate     917 non-null    float64\n",
      " 23  women_45_54_rate   917 non-null    float64\n",
      " 24  men_55plus_rate    917 non-null    float64\n",
      " 25  women_55plus_rate  365 non-null    float64\n",
      "dtypes: float64(25), object(1)\n",
      "memory usage: 186.4+ KB\n",
      "None\n",
      "         date  overall_rate  men_rate  women_rate  men_16_17_rate  \\\n",
      "0  1948-01-01           3.4       3.4         3.3             9.7   \n",
      "1  1948-02-01           3.8       3.6         4.5            13.0   \n",
      "2  1948-03-01           4.0       3.8         4.4            14.0   \n",
      "3  1948-04-01           3.9       3.8         4.3            11.6   \n",
      "4  1948-05-01           3.5       3.5         3.7             7.1   \n",
      "\n",
      "   women_16_17_rate  men_16_19_rate  women_16_19_rate  men_18_19_rate  \\\n",
      "0               8.8             9.4               7.2             9.5   \n",
      "1              13.2            10.8               8.9             9.2   \n",
      "2              11.4            11.9               8.6            10.3   \n",
      "3              10.6             9.8               9.2             8.6   \n",
      "4               5.4             7.6               6.1             8.6   \n",
      "\n",
      "   women_18_19_rate  ...  men_25_34_rate  women_25_34_rate  men_25_54_rate  \\\n",
      "0               6.8  ...             2.6               4.3             2.3   \n",
      "1               6.8  ...             2.7               5.1             2.6   \n",
      "2               7.3  ...             2.7               3.5             2.6   \n",
      "3               8.6  ...             3.2               3.8             2.8   \n",
      "4               7.0  ...             2.9               3.3             2.5   \n",
      "\n",
      "   women_25_54_rate  men_35_44_rate  women_35_44_rate  men_45_54_rate  \\\n",
      "0               2.8             2.1               1.8             2.3   \n",
      "1               3.7             2.5               2.6             2.6   \n",
      "2               3.3             2.6               3.0             2.4   \n",
      "3               3.5             2.7               3.5             2.5   \n",
      "4               3.1             2.4               3.0             2.3   \n",
      "\n",
      "   women_45_54_rate  men_55plus_rate  women_55plus_rate  \n",
      "0               2.1              3.0                NaN  \n",
      "1               3.3              2.9                NaN  \n",
      "2               3.3              2.8                NaN  \n",
      "3               3.1              2.9                NaN  \n",
      "4               2.9              3.1                NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "overall_rate         0\n",
      "men_rate             0\n",
      "women_rate           0\n",
      "men_16_17_rate       0\n",
      "women_16_17_rate     0\n",
      "men_16_19_rate       0\n",
      "women_16_19_rate     0\n",
      "men_18_19_rate       0\n",
      "women_18_19_rate     0\n",
      "men_16_24_rate       0\n",
      "women_16_24_rate     0\n",
      "men_20_24_rate       0\n",
      "women_20_24_rate     0\n",
      "men_25plus_rate      0\n",
      "women_25plus_rate    0\n",
      "men_25_34_rate       0\n",
      "women_25_34_rate     0\n",
      "men_25_54_rate       0\n",
      "women_25_54_rate     0\n",
      "men_35_44_rate       0\n",
      "women_35_44_rate     0\n",
      "men_45_54_rate       0\n",
      "women_45_54_rate     0\n",
      "men_55plus_rate      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(unemployment.info())  # Check for missing values and data types\n",
    "print(unemployment.head())  # Preview the data\n",
    "\n",
    "# Convert to datetime\n",
    "unemployment['date'] = pd.to_datetime(unemployment['date'], errors='coerce')\n",
    "\n",
    "unemployment.set_index('date', inplace=True)\n",
    "unemployment.sort_index(inplace=True)\n",
    "\n",
    "# Find and Fill all missing data\n",
    "unemployment.drop(columns=['women_55plus_rate'], inplace=True)\n",
    "print(unemployment.isnull().sum())\n",
    "unemployment.interpolate(method='linear', inplace=True) # use linear interpolation for filling NA values\n",
    "\n",
    "# Normalize data\n",
    "unemployment_scaler = StandardScaler()\n",
    "numeric_columns = unemployment.select_dtypes(include=['float64', 'int64']).columns\n",
    "unemployment[numeric_columns] = unemployment_scaler.fit_transform(unemployment[numeric_columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
